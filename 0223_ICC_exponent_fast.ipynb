{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2005727",
   "metadata": {},
   "source": [
    "### Background info\n",
    "\n",
    "Followed the 3-year reliability paper: https://doi.org/10.1016/j.neuroimage.2021.118516\n",
    "1. \"Using these source estimates, we then estimated the power of cortical activity in the canonical frequency bands: delta (2–4 Hz), theta (4–8 Hz), alpha (8–12 Hz), beta (15–30 Hz), low gamma (30–80 Hz), and high gamma (80–150 Hz). We used Welch's method for estimating power spectrum densities (PSD) per four-second epoch across each MEG recording, with 1-second sliding Hamming windows overlapping at 50%. We then standardized the PSD values at each frequency bin to the total power across the frequency spectrum. We then averaged PSD maps (ie. source estimates) across epochs for each participant to obtain one set of six PSD maps (one per frequency band) per participant per visit.\"\n",
    "2. \"We projected these maps onto the MNI ICBM152 brain template (Fonov et al., 2009) and applied a 3 mm FWHM smoothing kernel.\"\n",
    "3. \"Used single rater two-way mixed-effects model and absolute agreement definition, or ICC(A,1)... ICC estimates and their 95% confidence intervals were calculated using the Matlab Central file-exchange ICC.m function. This ICC calculation was applied at every vertex in the PSD maps to obtain spatially specific reliability estimates at each of the frequency bands. This resulted in an ICC map per frequency band.\"\n",
    "4. \"To further visualize the reliability of source power in each frequency band, regions of interest (Brainstorm “scouts”) in the frontal, parietal, temporal, and occipital lobes were applied to each participant's PSD map. The average power (relative to total spectral power) across each lobe was extracted for each participant and each visit. ICCs of these values were then calculated using the same ICC(A,1) model.\"\n",
    "- \"ICC .5 indicates poor reliability, values between .5 to .75 indicates moderate reliability, values between .75 and .9 indicates good reliability, and values greater than .9 indicate excellent reliability. Importantly, we evaluated the level of reliability based on the 95% confidence interval of the ICC estimate, not the estimate itself, since the interval reveals the chance that the true ICC value lands on any point between the bounds.\"\n",
    "\n",
    "### Morph\n",
    "\n",
    "Morph before sprint\n",
    "- The 3yr reliability paper applied a 3mm smoothing kernel\n",
    "Sources: \n",
    "- https://mne.tools/stable/auto_examples/inverse/morph_surface_stc.html\n",
    "\n",
    "### ICC\n",
    "\n",
    "https://github.com/raphaelvallat/pingouin/blob/dcfdc82bbc7f1ba5991b80717a5ca156617443e8/pingouin/reliability.py#L158\n",
    "ICC2 (single random raters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8656a6e",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cd901c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-loading files:\n",
      "Done loading files.\n"
     ]
    }
   ],
   "source": [
    "# IMPORT PACKAGES\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pingouin as pg\n",
    "import os\n",
    "import pickle\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# Things to loop through\n",
    "# dictionary = { \n",
    "#     \"NVAR008\": [\"251016\", \"251017\", \"251023\", \"251113\"], \n",
    "#     \"NVAR010\": [\"251027\", \"251028\", \"251103\", \"251124\"], \n",
    "#     \"NVAR011\": [\"251030\", \"251031\", \"251106\", \"251127\"]\n",
    "# }\n",
    "# runs = [\"rest1\", \"rest2\"]\n",
    "# bands = [\"delta\", \"theta\", \"alpha\", \"beta\", \"g_low\", \"g_high\"]\n",
    "\n",
    "base_dir = \"/home/isw3/sprint/output_noSSP_nomorph_winL4\"\n",
    "\n",
    "# Constants\n",
    "N_WINDOWS = 115 # 0 to 114\n",
    "N_VERTICES = 3 #8196\n",
    "N_ITERATIONS = 3 #100\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# WITHIN-SCAN\n",
    "\n",
    "# Filenames: Day 1, rest 1\n",
    "runnames = [\"sub_NVAR008_251016_rest1\", \n",
    "            \"sub_NVAR010_251027_rest1\"]\n",
    "\n",
    "r = 2\n",
    "\n",
    "# Pre-generate list of random windows\n",
    "windowAs = []\n",
    "for i in range(N_ITERATIONS):\n",
    "    np.random.seed(i)\n",
    "    windowA = np.random.choice(range(N_WINDOWS - r))\n",
    "    windowAs.append(windowA)\n",
    "\n",
    "\n",
    "# Pre-load all exponents\n",
    "# data_cache is a dictionary; format data_cache[runname][vertex] = series of exponents\n",
    "print(\"Pre-loading files:\")\n",
    "data_cache = {}\n",
    "for runname in runnames:\n",
    "    data_cache[runname] = {}\n",
    "    for vertex in range(N_VERTICES):\n",
    "        file_path = os.path.join(base_dir, \"output\", runname + \"_fooof_vertex\" + str(vertex) + \".csv\")\n",
    "        df_file = pd.read_csv(file_path, usecols=[\"exponent\"]) \n",
    "        data_cache[runname][vertex] = df_file[\"exponent\"].values \n",
    "print(\"Done loading files.\")\n",
    "\n",
    "\n",
    "def compute_icc_for_vertex(vertex, windowA): \n",
    "    \"\"\" \n",
    "    Computes ICC on a single vertex\n",
    "    Parameters: idx of one vertex; idx of one window pair\n",
    "    Returns: [vertex idx, icc value] -> will be one row \n",
    "    \"\"\"\n",
    "    print(f\"Now working on vertex {vertex} windowA {windowA}\")\n",
    "\n",
    "    try: \n",
    "        # Create dataframe of ratings\n",
    "        ratings = []\n",
    "        for runname in runnames: # Here, levels are runnames because there is only one per subject, but caution that this won't be true later\n",
    "            ratings.extend([\n",
    "                (runname, \"valA\", data_cache[runname][vertex][windowA]),\n",
    "                (runname, \"valB\", data_cache[runname][vertex][windowA + r])\n",
    "            ])\n",
    "        df_vertex = pd.DataFrame(ratings, columns=[\"TARGET\", \"RATER\", \"RATING\"])\n",
    "\n",
    "        # Compute ICC\n",
    "        #try: \n",
    "            #results = pg.intraclass_corr(data=df_vertex, targets='TARGET', raters='RATER', ratings='RATING')\n",
    "        #except Exception as e:\n",
    "            #print(f\"pg.intraclass_corr for {vertex} {windowA} returned error: {e}\")\n",
    "        #icc = results.loc[results['Type'] == 'ICC2', 'ICC'].values[0]\n",
    "        icc = windowA\n",
    "\n",
    "        # Return vertex and corresponding ICC\n",
    "        return [vertex, icc]\n",
    "    \n",
    "    except Exception as e: \n",
    "        print(f\"compute_icc_for_vertex for {vertex} {windowA} returned error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def compute_icc():\n",
    "    rows = []\n",
    "    for windowA in windowAs: \n",
    "        with Pool() as pool:\n",
    "            for result in pool.starmap(compute_icc_for_vertex, [(vertex, windowA) for vertex in range(N_VERTICES)]):\n",
    "                if result is not None:\n",
    "                    rows.extend([windowA] + result)\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=[\"WINDOW_A\", \"VERTEX\", \"ICC\"])\n",
    "    df[\"ICC_Z\"] = np.arctanh(df[\"ICC\"])\n",
    "\n",
    "    with open(os.path.join(base_dir, \"ICC_\" + str(r) + \".pkl\"), \"wb\") as f:\n",
    "        pickle.dump(df, f)\n",
    "\n",
    "\n",
    "compute_icc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e6c397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BETWEEN-SCANS: \n",
    "\n",
    "# Filenames: To start, always use visit_1_scan_1 as the reference\n",
    "comparison_dictionary = {\n",
    "    \"40min\" : {\n",
    "        \"sub_NVAR008\" : [\"sub_NVAR008_251016_rest1_fooof_vertex\", \"sub_NVAR008_251016_rest2_fooof_vertex\"], \n",
    "        \"sub_NVAR010\" : [\"sub_NVAR010_251027_rest1_fooof_vertex\", \"sub_NVAR010_251027_rest2_fooof_vertex\"], \n",
    "        \"sub_NVAR999\" : [\"sub_NVAR999_251016_rest1_fooof_vertex\", \"sub_NVAR999_251016_rest2_fooof_vertex\"]\n",
    "    },\n",
    "    \"day\" : {\n",
    "        \"sub_NVAR008\" : [\"sub_NVAR008_251016_rest1_fooof_vertex\", \"sub_NVAR008_251017_rest1_fooof_vertex\"], \n",
    "        \"sub_NVAR010\" : [\"sub_NVAR010_251027_rest1_fooof_vertex\", \"sub_NVAR010_251028_rest1_fooof_vertex\"], \n",
    "        \"sub_NVAR999\" : [\"sub_NVAR999_251016_rest1_fooof_vertex\", \"sub_NVAR999_251017_rest1_fooof_vertex\"]\n",
    "    },\n",
    "    \"week\" : {\n",
    "        \"sub_NVAR008\" : [\"sub_NVAR008_251016_rest1_fooof_vertex\", \"sub_NVAR008_251023_rest1_fooof_vertex\"], \n",
    "        \"sub_NVAR010\" : [\"sub_NVAR010_251027_rest1_fooof_vertex\", \"sub_NVAR010_251103_rest1_fooof_vertex\"], \n",
    "        \"sub_NVAR999\" : [\"sub_NVAR999_251016_rest1_fooof_vertex\", \"sub_NVAR999_251023_rest1_fooof_vertex\"]\n",
    "    },\n",
    "    \"month\" : {\n",
    "        \"sub_NVAR008\" : [\"sub_NVAR008_251016_rest1_fooof_vertex\", \"sub_NVAR008_251113_rest1_fooof_vertex\"], \n",
    "        \"sub_NVAR010\" : [\"sub_NVAR010_251027_rest1_fooof_vertex\", \"sub_NVAR010_251124_rest1_fooof_vertex\"], \n",
    "        \"sub_NVAR999\" : [\"sub_NVAR999_251016_rest1_fooof_vertex\", \"sub_NVAR999_251113_rest1_fooof_vertex\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Test with sparse r-values\n",
    "r = 0 # Just the same window in both scans\n",
    "\n",
    "scale = \"40min\"\n",
    "\n",
    "# Initialize rows, which will turn into the dataframe that will contain ICC estimates for each vertex\n",
    "rows = []\n",
    "\n",
    "# 100 iterations\n",
    "for i in range(100): \n",
    "\n",
    "    # Randomly sample two time windows that are separated by a distance r\n",
    "    np.random.seed(i)\n",
    "    windowA = np.random.choice(range(N_WINDOWS - r))\n",
    "    windowB = windowA + r\n",
    "\n",
    "    # Loop through all vertices\n",
    "    for vertex in range(N_VERTICES):\n",
    "        \n",
    "        # Since ICC has to be computed separately for each vertex, you need a mini-dataframe for each one\n",
    "        df_vertex = pd.DataFrame(columns=[\"TARGET\", \"RATER\", \"RATING\"])\n",
    "\n",
    "        # For each subject, extract features from time windows\n",
    "        for subject in comparison_dictionary[scale]: \n",
    "\n",
    "            # Load files for this vertex\n",
    "            fileA = pd.read_csv(os.path.join(base_dir, \"output\", comparison_dictionary[scale][subject][0] + str(vertex) + \".csv\"))\n",
    "            fileB = pd.read_csv(os.path.join(base_dir, \"output\", comparison_dictionary[scale][subject][1] + str(vertex) + \".csv\"))\n",
    "\n",
    "            # Extract features from windows A and B - call these valA and valB\n",
    "            valA = fileA.loc[windowA, \"exponent\"]\n",
    "            valB = fileB.loc[windowB, \"exponent\"]\n",
    "\n",
    "            # Add the pair of values to the dataframe\n",
    "            df_vertex.loc[len(df_vertex)] = [subject, \"valA\", valA]\n",
    "            df_vertex.loc[len(df_vertex)] = [subject, \"valB\", valB]\n",
    "\n",
    "        # At this point, df_vertex has two vectors - one containing each valA per subject, and one of each valB\n",
    "        # Compute ICC(A, 1) (single-rater) (ICC2)\n",
    "        results = pg.intraclass_corr(data=df_vertex, targets='TARGET', raters='RATER', ratings='RATING')\n",
    "        icc2 = results.loc[results['Type'] == 'ICC2', 'ICC'].values[0]\n",
    "\n",
    "        # Add ICC for this vertex to the total output\n",
    "        rows.append([vertex, icc2])\n",
    "\n",
    "# Save the entire thing\n",
    "# There will be 100 ICC estimates for each vertex, meaning that the output will have length N_VERTICES*100\n",
    "df = pd.DataFrame(rows, columns=[\"VERTEX\", \"ICC\"])\n",
    "# Later, need to Fisher transform per vertex\n",
    "with open(os.path.join(base_dir, \"ICC_\" + scale + str(r) + \".pkl\"), \"wb\") as f: \n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91577add",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b0f7d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa89acbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BETWEEN-RUN\n",
    "\n",
    "# Filenames\n",
    "subject1_file = \"sub_NVAR008_251016_rest1_fooof_window\"\n",
    "subject2_file = \"sub_NVAR010_251027_rest1_fooof_window\"\n",
    "\n",
    "r = 2\n",
    "\n",
    "for i in range(100): \n",
    "\n",
    "    # Get indices of valA and valB\n",
    "    np.random.seed(i)\n",
    "    windowA = np.random.choice(range(N_WINDOWS - r + 1))\n",
    "    windowB = windowA + r\n",
    "\n",
    "    # The dataframe will have the ICC (and CI) at each vertex\n",
    "    df = pd.DataFrame(columns=[\"VERTEX\", \"ICC2\", \"CI\"])\n",
    "\n",
    "    # Loop through vertices\n",
    "    for vertex in range(N_VERTICES):\n",
    "        \n",
    "        # Since ICC has to be computed separately for each vertex, you need a dataframe for each vertex\n",
    "        df_vertex = pd.DataFrame(columns=[\"TARGET\", \"RATER\", \"RATING\"])\n",
    "\n",
    "        # For each participant, for each vertex, extract valA and valB\n",
    "        for subject_file in [subject1_file, subject2_file]: \n",
    "\n",
    "            # Extract subject name\n",
    "            subject = re.search(r'sub_[A-Z0-9]+', subject_file).group()\n",
    "\n",
    "            # Load file\n",
    "            valA_file = pd.read_csv(os.path.join(base_dir, \"output\", subject_file + str(windowA) + \".csv\"))\n",
    "            valB_file = pd.read_csv(os.path.join(base_dir, \"output\", subject_file + str(windowB) + \".csv\"))\n",
    "\n",
    "            # Extract values\n",
    "            valA = valA_file.loc[vertex, \"exponent\"]\n",
    "            valB = valB_file.loc[vertex, \"exponent\"]\n",
    "\n",
    "            print(vertex)\n",
    "            print(subject)\n",
    "            print(\"valA \" + str(valA))\n",
    "            print(\"valB \" + str(valB))\n",
    "\n",
    "            # Add the pair of values\n",
    "            df_vertex.loc[len(df_vertex)] = [subject, \"valA\", valA]\n",
    "            df_vertex.loc[len(df_vertex)] = [subject, \"valB\", valB]\n",
    "\n",
    "        # Compute ICC on this vertex\n",
    "        results = pg.intraclass_corr(data=df_vertex, targets='TARGET', raters='RATER', ratings='RATING')\n",
    "        icc2 = results.loc[1, 'ICC']\n",
    "        ci = results.loc[1, \"CI95%\"]\n",
    "\n",
    "        # Add to big df\n",
    "        df.loc[len(df)] = [vertex, icc2, ci]\n",
    "\n",
    "# Save the entire thing\n",
    "with open(os.path.join(base_dir, \"ICC_\" + str(r) + \".pkl\"), \"wb\") as f: \n",
    "    pickle.dump(df, f)\n",
    "\n",
    "# Fisher transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506b098d",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_file = \"sub_NVAR008_251016_rest1_fooof_window\"\n",
    "valA_file = pd.read_csv(os.path.join(base_dir, \"output\", subject_file + str(windowA) + \".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cee3d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"C:/meg/0215_NVAR_sprint_fooof\"\n",
    "prefix = \"sub_NVAR008_251016_rest1\"\n",
    "input_path = os.path.join(base_path, prefix)\n",
    "\n",
    "print(\"Path to stc: \" + input_path)\n",
    "stc = mne.read_source_estimate(input_path)\n",
    "print(\"stc loaded\")\n",
    "\n",
    "print(\"Morphing to fsaverage:\")\n",
    "subject = re.search(r'sub_[A-Z0-9]+', prefix).group()\n",
    "morph = mne.compute_source_morph(\n",
    "    stc,\n",
    "    subject_from = subject, \n",
    "    subject_to = \"fsaverage\", # to fsaverage\n",
    "    subjects_dir = \"C:/meg/NVAR_ICC_day/MRI/freesurfer\"\n",
    "    )\n",
    "stc_morphed = morph.apply(stc)\n",
    "stc_morphed.save(os.path.join(base_path, prefix + \"_morphed\"))\n",
    "print(\"Morph done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b336082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPARSE ICC\n",
    "# Reference point always visit1_scan1\n",
    "\n",
    "base_filename = \"sub_NVAR008_251016_rest1_fooof_window\"\n",
    "\n",
    "r = 2\n",
    "valA = 0\n",
    "valB = valA + r\n",
    "\n",
    "valAfile = pd.read_csv(os.path.join(base_dir, \"output\", base_filename + str(valA) + \".csv\"))\n",
    "valBfile = pd.read_csv(os.path.join(base_dir, \"output\", base_filename + str(valB) + \".csv\"))\n",
    "\n",
    "# Loop through vertices\n",
    "for vertex in range(len(example_stc.vertices)):\n",
    "\n",
    "    # Since ICC has to be computed separately for each vertex, you need a dataframe for each vertex\n",
    "    df_vertex = pd.DataFrame(columns=[\"TARGET\", \"RATER\", \"RATING\"])\n",
    "\n",
    "    # Get valA for this vertex\n",
    "\n",
    "                            valA = stc.data[vertex, window]\n",
    "                        print(valA)\n",
    "                        valB = stc.data[vertex, window+2]\n",
    "                        print(valB)\n",
    "\n",
    "                        # Add the pair of values\n",
    "                        df_vertex.loc[len(df_vertex)] = [\"_\".join([subject, session, run]), \"valA\", valA]\n",
    "                        df_vertex.loc[len(df_vertex)] = [\"_\".join([subject, session, run]), \"valB\", valB]\n",
    "\n",
    "    # Get valB for this vertex \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Loop through band, subject, scan, and run\n",
    "for band in bands: \n",
    "\n",
    "    # Create a dataframe just for this band\n",
    "    # The dataframe will have the ICC (and CI) at each vertex\n",
    "    df = pd.DataFrame(columns=[\"VERTEX\", \"ICC2\", \"CI\"])\n",
    "\n",
    "    for vertex in range(len(stc.vertices)):\n",
    "\n",
    "        # Create a dataframe just for this vertex\n",
    "        df_vertex = pd.DataFrame(columns=[\"TARGET\", \"RATER\", \"RATING\"]) # subject_scan_run, valA/B, power\n",
    "        # why is target subject_scan_run? because otherwise there'd be too much variability. We are trying to estimate ICC WITHIN a run\n",
    "\n",
    "        # Loop through all runs for all sessions for all subjects\n",
    "        for subject in dictionary: \n",
    "            for session in dictionary[subject]:\n",
    "                for run in runs: \n",
    "\n",
    "                    # Read data\n",
    "                    # TODO\n",
    "\n",
    "                    # Loop through run windows; the run has 55 windows, numbered 0-54\n",
    "                    for window in range(53): # Need to stop at 52 so that the final valB is = 54\n",
    "                        print(\"Value A: \" + str(window))\n",
    "                        print(\"Value B: \" + str(window+2))\n",
    "\n",
    "                        valA = stc.data[vertex, window]\n",
    "                        print(valA)\n",
    "                        valB = stc.data[vertex, window+2]\n",
    "                        print(valB)\n",
    "\n",
    "                        # Add the pair of values\n",
    "                        df_vertex.loc[len(df_vertex)] = [\"_\".join([subject, session, run]), \"valA\", valA]\n",
    "                        df_vertex.loc[len(df_vertex)] = [\"_\".join([subject, session, run]), \"valB\", valB]\n",
    "\n",
    "        # Compute ICC on this vertex\n",
    "        results = pg.intraclass_corr(data=df_vertex, targets='TARGET', raters='RATER', ratings='RATING')\n",
    "        icc2 = results.loc[1, 'ICC']\n",
    "        ci = results.loc[1, \"CI95%\"]\n",
    "\n",
    "    # Add to big df\n",
    "    df.loc[len(df)] = [vertex, icc2, ci]\n",
    "\n",
    "    # Save the entire thing\n",
    "    with open(\"C:/meg/NVAR_ICC/ICC_inrun_\" + band + \".pkl\", \"wb\") as f: \n",
    "        pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b516f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACROSS RUNS: REST1 VS REST2\n",
    "# Call values from rest1 \"valA\" and values from rest2 \"valB\"\n",
    "\n",
    "# Loop through band, subject, scan, and run\n",
    "for band in bands: \n",
    "\n",
    "    # Create a dataframe just for this band\n",
    "    # The dataframe will have the ICC (and CI) at each vertex\n",
    "    df = pd.DataFrame(columns=[\"VERTEX\", \"ICC2\", \"CI\"])\n",
    "\n",
    "    for vertex in range(len(stc.vertices)):\n",
    "\n",
    "        # Create a dataframe just for this vertex\n",
    "        df_vertex = pd.DataFrame(columns=[\"TARGET\", \"RATER\", \"RATING\"]) # subject_scan, valA/B, power\n",
    "        # why is target subject_scan_run? because otherwise there'd be too much variability. We are trying to estimate ICC within a run \n",
    "\n",
    "        # Loop through all runs for all sessions for all subjects\n",
    "        for subject in dictionary: \n",
    "            for session in dictionary[subject]:\n",
    "\n",
    "                # Loop through run windows; the run has 55 windows, numbered 0-54\n",
    "                for window in range(55): \n",
    "\n",
    "                    # Get file for runA\n",
    "                    # Read data\n",
    "                    # TODO\n",
    "                    stc_rest1 = \n",
    "                    valA = stc_rest1.data[vertex, window]\n",
    "\n",
    "                    # Get file for runB\n",
    "                    stc_rest2 = \n",
    "                    valB = stc_rest2.data[vertex, window]\n",
    "\n",
    "                    # Add the pair of values\n",
    "                    df_vertex.loc[len(df_vertex)] = [\"_\".join([subject, session]), \"valA\", valA]\n",
    "                    df_vertex.loc[len(df_vertex)] = [\"_\".join([subject, session]), \"valB\", valB]\n",
    "\n",
    "        # Compute ICC on this vertex\n",
    "        results = pg.intraclass_corr(data=df_vertex, targets='TARGET', raters='RATER', ratings='RATING')\n",
    "        icc2 = results.loc[1, 'ICC']\n",
    "        ci = results.loc[1, \"CI95%\"]\n",
    "\n",
    "    # Add to big df\n",
    "    df.loc[len(df)] = [vertex, icc2, ci]\n",
    "\n",
    "    # Save the entire thing\n",
    "    with open(\"C:/meg/NVAR_ICC/ICC_rest1-vs-rest2_\" + band + \".pkl\", \"wb\") as f: \n",
    "        pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b9c0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACROSS DAYS: TODO!!!!!!!\n",
    "# Call values from rest1 \"valA\" and values from rest2 \"valB\"\n",
    "\n",
    "# Loop through band, subject, scan, and run\n",
    "for band in bands: \n",
    "\n",
    "    # Create a dataframe just for this band\n",
    "    # The dataframe will have the ICC (and CI) at each vertex\n",
    "    df = pd.DataFrame(columns=[\"VERTEX\", \"ICC2\", \"CI\"])\n",
    "\n",
    "    for vertex in range(len(stc.vertices)):\n",
    "\n",
    "        # Create a dataframe just for this vertex\n",
    "        df_vertex = pd.DataFrame(columns=[\"TARGET\", \"RATER\", \"RATING\"]) # subject_scan, valA/B, power\n",
    "        # why is target subject_scan_run? because otherwise there'd be too much variability. We are trying to estimate ICC within a run \n",
    "\n",
    "        # Loop through all runs for all sessions for all subjects\n",
    "        for subject in dictionary: \n",
    "\n",
    "\n",
    "            # \n",
    "            for session in dictionary[subject]:\n",
    "\n",
    "                # Loop through run windows; the run has 55 windows, numbered 0-54\n",
    "                for window in range(55): \n",
    "\n",
    "                    # Get file for runA\n",
    "                    # Read data\n",
    "                    # TODO\n",
    "                    stc_rest1 = \n",
    "                    valA = stc_rest1.data[vertex, window]\n",
    "\n",
    "                    # Get file for runB\n",
    "                    stc_rest2 = \n",
    "                    valB = stc_rest2.data[vertex, window]\n",
    "\n",
    "                    # Add the pair of values\n",
    "                    df_vertex.loc[len(df_vertex)] = [\"_\".join([subject, session]), \"valA\", valA]\n",
    "                    df_vertex.loc[len(df_vertex)] = [\"_\".join([subject, session]), \"valB\", valB]\n",
    "\n",
    "        # Compute ICC on this vertex\n",
    "        results = pg.intraclass_corr(data=df_vertex, targets='TARGET', raters='RATER', ratings='RATING')\n",
    "        icc2 = results.loc[1, 'ICC']\n",
    "        ci = results.loc[1, \"CI95%\"]\n",
    "\n",
    "    # Add to big df\n",
    "    df.loc[len(df)] = [vertex, icc2, ci]\n",
    "\n",
    "    # Save the entire thing\n",
    "    with open(\"C:/meg/NVAR_ICC/ICC_rest1-vs-rest2_\" + band + \".pkl\", \"wb\") as f: \n",
    "        pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3778bbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DAYS AS RATERS\n",
    "\"\"\"\n",
    "Shape of stc_average: \n",
    "array([[0.0053271 ],\n",
    "       [0.00452035],\n",
    "       [0.005533  ],\n",
    "       ...,\n",
    "       [0.00313858],\n",
    "       [0.003465  ],\n",
    "       [0.00346861]], shape=(20484, 1), dtype=float32)\n",
    "\"\"\"\n",
    "\n",
    "# Loop through bands\n",
    "# for band in bands: \n",
    "band = \"alpha\" # test\n",
    "\n",
    "# Vertex-wise ICC\n",
    "df = pd.DataFrame(columns=[\"VERTEX\", \"ICC2\", \"CI\"])\n",
    "\n",
    "# Loop through vertices\n",
    "# There are 20484 vertices\n",
    "for vertex in range(20484): \n",
    "\n",
    "    df_vertex = pd.DataFrame(columns=[\"TARGET\", \"RATER\", \"RATING\"]) # subject, session, power\n",
    "\n",
    "    # Add the value for this vertex for average-morph for each subject/session \n",
    "    for subject in dictionary: \n",
    "        for session in dictionary[subject]: \n",
    "            \n",
    "            stc_dir = os.path.join(base_dir, \"sub_\" + subject, session, \"beamformer\", \"stc\")\n",
    "            stc_average_name = os.path.join(stc_dir, \"sub_\" + subject + \"_average_raw_tsss_beamformer_\" + band + \"_stc_morphed\")\n",
    "            stc = mne.read_source_estimate(stc_average_name)\n",
    "            power = stc.data[vertex]\n",
    "\n",
    "            df_vertex.loc[len(df_vertex)] = [subject, session, power[0]]\n",
    "\n",
    "    # Compute ICC on this\n",
    "    results = pg.intraclass_corr(data=df_vertex, targets='TARGET', raters='RATER', ratings='RATING')\n",
    "    icc2 = results.loc[1, 'ICC']\n",
    "    ci = results.loc[1, \"CI95%\"]\n",
    "\n",
    "    # Add to big df\n",
    "    df.loc[len(df)] = [vertex, icc2, ci]\n",
    "\n",
    "    # Save the entire thing\n",
    "    with open(\"C:/meg/NVAR_ICC/vertexwise_ICC_\" + band + \".pkl\", \"wb\") as f: \n",
    "        pkl.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0247034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot whole-brain ICC maps\n",
    "\n",
    "def plot_stc_grid(stcs, labels):\n",
    "    \"\"\"\n",
    "    Plot a list of STCs in an nx3 grid (dorsal, right lateral, left lateral).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    stcs : list of SourceEstimate\n",
    "        One STC per row.\n",
    "    labels : list of str\n",
    "        Row labels. \n",
    "    \"\"\"\n",
    "    views = ['lateral', 'dorsal', 'lateral']\n",
    "    hemis = ['rh', 'both', 'lh']\n",
    "\n",
    "    clim = dict(kind='value', lims=[0, 0.5, 1])\n",
    "    colormap = 'viridis'\n",
    "\n",
    "    n = len(stcs)\n",
    "    fig, axes = plt.subplots(n, 4, figsize=(13, 4 * n),\n",
    "                         gridspec_kw=dict(width_ratios=[1, 1, 1, 0.05]))\n",
    "\n",
    "    if n == 1:\n",
    "        axes = axes[np.newaxis, :]\n",
    "\n",
    "    for row, stc in enumerate(stcs):\n",
    "        for col, (view, hemi) in enumerate(zip(views, hemis)):\n",
    "\n",
    "            brain = stc.plot(\n",
    "                subject='fsaverage',\n",
    "                subjects_dir=\"C:/meg/NVAR_ICC_day/MRI/freesurfer/\",\n",
    "                hemi=hemi,\n",
    "                views=view,\n",
    "                clim=clim,\n",
    "                colormap= colormap, \n",
    "                background='white', \n",
    "                #surface = \"pial\", \n",
    "                colorbar = False\n",
    "            )\n",
    "\n",
    "            img = brain.screenshot()\n",
    "            axes[row, col].imshow(img)\n",
    "            axes[row, col].axis('off')\n",
    "            plt.close('all')\n",
    "\n",
    "\n",
    "        mne.viz.plot_brain_colorbar(axes[row, 3], clim, colormap, label=\"ICC\")\n",
    "\n",
    "        axes[row, 0].text(-0.1, 0.5, labels[row], transform=axes[row, 0].transAxes,\n",
    "                  fontsize=20, va='center', ha='right', rotation=0)\n",
    "\n",
    "    col_titles = ['Right Lateral', 'Dorsal', 'Left Lateral']\n",
    "    for col, title in enumerate(col_titles):\n",
    "        axes[0, col].set_title(title, fontsize=20)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def make_and_plot_stc(files, labels): \n",
    "    \"\"\"\n",
    "    Given a list of paths to pickle files, makes a list of stcs, then passes them to a function for plotting\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pkls : list of pkl, each a dataframe with columns: vertex, ICC2, CI\n",
    "    labels : list of str\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    stcs = []\n",
    "\n",
    "    for file in files: \n",
    "\n",
    "        with open(pkl, \"rb\") as f: \n",
    "            df = pickle.load(f)\n",
    "\n",
    "        stc = mne.SourceEstimate(\n",
    "            data = df[\"ICC2\"].to_numpy(),\n",
    "            vertices = [np.arange(0, 10242), np.arange(0, 10242)], \n",
    "            tmin=0,\n",
    "            tstep=1,\n",
    "            subject=\"fsaverage\"\n",
    "        )\n",
    "\n",
    "        stcs.append(stc)\n",
    "    \n",
    "    return plot_stc_grid(stcs, labels)\n",
    "\n",
    "\n",
    "fig = make_and_plot_stc(\n",
    "    pkls=[\"C:/meg/NVAR_ICC_day/ICC_alpha.pkl\", \"C:/meg/NVAR_ICC_day/ICC_beta.pkl\", \"C:/meg/NVAR_ICC_day/ICC_g_low.pkl\"],\n",
    "    labels=['Alpha', 'Beta', 'Gamma']\n",
    ")\n",
    "\n",
    "fig.savefig('C:/meg/NVAR_ICC_day/brain_grid.png', dpi=300, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
