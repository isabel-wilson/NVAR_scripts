{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be514149",
   "metadata": {},
   "source": [
    "### Temporary: sbatch script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b84bd4",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH --time=10:00:00\n",
    "#SBATCH --mem=0\n",
    "#SBATCH --cpus-per-task=1\n",
    "#SBATCH --ntasks-per-node=192\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --array=0-47\n",
    "\n",
    "# Create the logs directory if it does not exist\n",
    "mkdir -p ./logs/outputs\n",
    "mkdir -p ./logs/errors\n",
    "\n",
    "# Activate the virtual environment\n",
    "module load scipy-stack/2025a\n",
    "source $HOME/env/bin/activate\n",
    "\n",
    "# Note: Outputs will go into \"outputs\" folder, so be sure to backup the results of last step\n",
    "mkdir images # For whitened PSD plots\n",
    "\n",
    "# Run the script\n",
    "inputs=(\"sub_NVAR008_251016_rest1\" \"sub_NVAR008_251016_rest1\" \"sub_NVAR008_251016_rest2\" \"sub_NVAR008_251016_rest2\" \"sub_NVAR008_251017_rest1\" \"sub_NVAR008_251017_rest1\" \"sub_NVAR008_251017_rest2\" \"sub_NVAR008_251017_rest2\" \"sub_NVAR008_251023_rest1\" \"sub_NVAR008_251023_rest1\" \"sub_NVAR008_251023_rest2\" \"sub_NVAR008_251023_rest2\" \"sub_NVAR008_251113_rest1\" \"sub_NVAR008_251113_rest1\" \"sub_NVAR008_251113_rest2\" \"sub_NVAR008_251113_rest2\" \"sub_NVAR010_251027_rest1\" \"sub_NVAR010_251027_rest1\" \"sub_NVAR010_251027_rest2\" \"sub_NVAR010_251027_rest2\" \"sub_NVAR010_251028_rest1\" \"sub_NVAR010_251028_rest1\" \"sub_NVAR010_251028_rest2\" \"sub_NVAR010_251028_rest2\" \"sub_NVAR010_251103_rest1\" \"sub_NVAR010_251103_rest1\" \"sub_NVAR010_251103_rest2\" \"sub_NVAR010_251103_rest2\" \"sub_NVAR010_251124_rest1\" \"sub_NVAR010_251124_rest1\" \"sub_NVAR010_251124_rest2\" \"sub_NVAR010_251124_rest2\" \"sub_NVAR011_251030_rest1\" \"sub_NVAR011_251030_rest1\" \"sub_NVAR011_251030_rest2\" \"sub_NVAR011_251030_rest2\" \"sub_NVAR011_251031_rest1\" \"sub_NVAR011_251031_rest1\" \"sub_NVAR011_251031_rest2\" \"sub_NVAR011_251031_rest2\" \"sub_NVAR011_251106_rest1\" \"sub_NVAR011_251106_rest1\" \"sub_NVAR011_251106_rest2\" \"sub_NVAR011_251106_rest2\" \"sub_NVAR011_251127_rest1\" \"sub_NVAR011_251127_rest1\" \"sub_NVAR011_251127_rest2\" \"sub_NVAR011_251127_rest2\")\n",
    "input=${inputs[$SLURM_ARRAY_TASK_ID]}\n",
    "python -u /home/isw3/scratch/sprint/0221_post_sprint.py --idx \"$input\"\n",
    "\n",
    "# Deactivate the virtual environment\n",
    "deactivate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020fcacf",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6cb6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that code for visualizing sprint psd outputs is in 0205_plot_param.ipynb\n",
    "\n",
    "# IMPORT PACKAGES\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle as pkl\n",
    "import mne\n",
    "import copy as copy\n",
    "from pathlib import Path\n",
    "from mne.time_frequency import psd_array_welch\n",
    "import argparse\n",
    "\n",
    "# GET ARGUMENT\n",
    "#prefix = \"sub_NVAR008_251016_rest1\"\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--idx\", type=str, required=True)\n",
    "args = parser.parse_args()\n",
    "prefix = args.idx\n",
    "print(f\"Now working on {prefix}\")\n",
    "\n",
    "# SET PATHS\n",
    "base_dir = \"C:/meg/0215_NVAR_sprint_fooof\"\n",
    "\n",
    "# CONSTANTS\n",
    "N_WINDOWS = 115\n",
    "N_VERTICES = 8196\n",
    "# Set \"example_stc\" - this is the original beamformed stc outputted by the generic task-free processing script\n",
    "# it will be used to get vertex numbers where relevant\n",
    "example_stc = mne.read_source_estimate(os.path.join(base_dir, \"example_stc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b103962a",
   "metadata": {},
   "source": [
    "### Postprocess fooof output: Reformat csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fe5d9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REFORMAT FOOOF CSVS \n",
    "\n",
    "def reformat(prefix):\n",
    "    \"\"\"\n",
    "    Input: files prefix_vertex_index.csv (note: vertex index, not vertex number) where each row is window\n",
    "    Output: files prefix_window_num.csv where each row is vertex index\n",
    "    \"\"\"\n",
    "    for window in range(N_WINDOWS): # Number of windows\n",
    "        rows = []\n",
    "\n",
    "        for data_index in range(N_VERTICES): # Number of vertices\n",
    "\n",
    "            og_csv_path = f\"{base_dir}/output/{prefix}_fooof_vertex{data_index}.csv\"\n",
    "            og_df = pd.read_csv(og_csv_path)\n",
    "\n",
    "            row = og_df.iloc[window].copy()\n",
    "            row['vertex_index'] = data_index\n",
    "            rows.append(row)\n",
    "\n",
    "        pd.DataFrame(rows).to_csv(f\"{base_dir}/output/{prefix}_fooof_window{window}.csv\", index=False)\n",
    "\n",
    "reformat(prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992129e5",
   "metadata": {},
   "source": [
    "### Postprocess SPRINT output: Break into stcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad461026",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Unexpected start frequency: 0.5",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(example_stc.vertices[\u001b[32m0\u001b[39m]) + \u001b[38;5;28mlen\u001b[39m(example_stc.vertices[\u001b[32m1\u001b[39m]) == N_VERTICES\n\u001b[32m     17\u001b[39m freq_dim = output[\u001b[33m\"\u001b[39m\u001b[33mfreqs\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m2\u001b[39m:\u001b[32m161\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m freq_dim[\u001b[32m0\u001b[39m] > \u001b[32m1.5\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnexpected start frequency: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfreq_dim[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[32m39.5\u001b[39m < freq_dim[-\u001b[32m1\u001b[39m] < \u001b[32m40.5\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnexpected end frequency: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfreq_dim[-\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFrequency range: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfreq_dim[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfreq_dim[-\u001b[32m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Hz (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(freq_dim)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m bins)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAssertionError\u001b[39m: Unexpected start frequency: 0.5"
     ]
    }
   ],
   "source": [
    "# CREATE INDIVIDUAL STCS\n",
    "# One stc for each time window\n",
    "# You should have N_WINDOWS stcs, and each is PSD vs freq\n",
    "\n",
    "# Do not log it\n",
    "# Starts at 2 because I noticed during whitening the model fit worse there\n",
    "# Ends at 161 because that's 40 Hz\n",
    "\n",
    "# Load sprint output\n",
    "with open(os.path.join(base_dir, \"output\", prefix + \"_sprint.pkl\"), \"rb\") as f:\n",
    "    output = pkl.load(f)\n",
    "\n",
    "# Check dimensions of sprint output\n",
    "assert output[\"TF\"].shape[0] == N_VERTICES, f\"Expected {N_VERTICES} vertices, got {output['TF'].shape[0]}\"\n",
    "assert output[\"TF\"].shape[1] == N_WINDOWS, f\"Expected {N_WINDOWS} windows, got {output['TF'].shape[1]}\"\n",
    "assert len(example_stc.vertices[0]) + len(example_stc.vertices[1]) == N_VERTICES\n",
    "freq_dim = output[\"freqs\"][2:161]\n",
    "assert freq_dim[0] > 1.5, f\"Unexpected start frequency: {freq_dim[0]}\"\n",
    "assert 39.5 < freq_dim[-1] < 40.5, f\"Unexpected end frequency: {freq_dim[-1]}\"\n",
    "print(f\"Frequency range: {freq_dim[0]:.2f} to {freq_dim[-1]:.2f} Hz ({len(freq_dim)} bins)\")\n",
    "\n",
    "TF_cropped = output[\"TF\"][:, :, 2:161]\n",
    "\n",
    "for window in range(TF_cropped.shape[1]): \n",
    "    slice_window = TF_cropped[:, window, :]\n",
    "    new_stc = mne.SourceEstimate(\n",
    "        data = slice_window, \n",
    "        vertices = example_stc.vertices, \n",
    "        tmin = 0.5, \n",
    "        tstep = 0.25\n",
    "    )\n",
    "    new_stc.save(os.path.join(f\"{base_dir}/output/{prefix}_sprint_window{window}\"), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d798a7fe",
   "metadata": {},
   "source": [
    "### Whitening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0b2936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUBTRACTION\n",
    "# Do one window at a time\n",
    "# Input: sprint_window.stc, fooof_window.csv\n",
    "# Output: _whitened.stc\n",
    "\n",
    "# freq_dim was computed in an earlier step, but it's worth checking again\n",
    "freq_dim = output[\"freqs\"][2:161]\n",
    "assert freq_dim[0] > 1.5, f\"Unexpected start frequency: {freq_dim[0]}\"\n",
    "assert 39.5 < freq_dim[-1] < 40.5, f\"Unexpected end frequency: {freq_dim[-1]}\"\n",
    "print(f\"Frequency range: {freq_dim[0]:.2f} to {freq_dim[-1]:.2f} Hz ({len(freq_dim)} bins)\")\n",
    "\n",
    "for window in range(N_WINDOWS): \n",
    "    print(str(window))\n",
    "\n",
    "    ##### Prep: Load files\n",
    "    stc = mne.read_source_estimate(f\"{base_dir}/output/{prefix}_sprint_window{window}\")\n",
    "    csv = pd.read_csv(f\"{base_dir}/output/{prefix}_fooof_window{window}.csv\")\n",
    "\n",
    "\n",
    "    ##### PSD Model (exponential)\n",
    "\n",
    "    # This is the list where you will put the model for each vertex\n",
    "    rows = []\n",
    "\n",
    "    # Get average offset and exponent for this subject (to be used for fixing bad values)\n",
    "    average_exponent = np.nanmean(csv.iloc[:, 2])\n",
    "    average_offset = np.nanmean(csv.iloc[:, 1])\n",
    "\n",
    "    # Loop through rows of csv file\n",
    "    for i in range(len(csv)): \n",
    "        \n",
    "        # Collect values\n",
    "        vertex = int(csv.iloc[i, 0])\n",
    "        exponent = csv.iloc[i, 2]\n",
    "        offset = csv.iloc[i, 1]\n",
    "\n",
    "        # Make sure values look okay; if there are errors, replace with subject mean\n",
    "        if type(exponent) != np.float64 or not np.isfinite(exponent): \n",
    "            print(f\"error in exponent for subject {prefix} window {window} vertex {vertex}, setting to subject average\")\n",
    "            exponent = average_exponent\n",
    "        if type(offset) != np.float64 or not np.isfinite(offset): \n",
    "            print(f\"error in offset for subject {prefix} window {window} vertex {vertex}, setting to subject average\")\n",
    "            offset = average_offset\n",
    "\n",
    "        # Compute exponential for this vertex\n",
    "        # In linear space - not in log space\n",
    "        exponential = 10**(offset - (np.log10(freq_dim))*exponent)\n",
    "\n",
    "        # Add the exponential for this vertex to the \"rows\" list\n",
    "        rows.append(exponential)\n",
    "\n",
    "    # The final array of all exponentials for all vertices (cleaned up)\n",
    "    model = np.array(rows).squeeze()\n",
    "\n",
    "    ##### Subtraction\n",
    "\n",
    "    # Check that dims are same first\n",
    "    assert model.shape == stc.data.shape, \\\n",
    "    f\"Shape mismatch: model {model.shape} vs stc.data {stc.data.shape}\"\n",
    "\n",
    "    # Whiten PSD: Subtract model PSD from real PSD\n",
    "    # model: comes in not logged (linear)\n",
    "    # stc data: comes in not logged (linear)\n",
    "    # frequency is linear for both\n",
    "    # subtraction happens in linear-linear space\n",
    "    whitened_psd = stc.data - model\n",
    "\n",
    "    # Create a plot for whitened PSD, and save it for review\n",
    "    plt.figure()\n",
    "    plt.plot(freq_dim, np.average(model.T, axis=1), label=\"Aperiodic fit\", color=\"blue\")\n",
    "    plt.plot(stc.times, np.average(stc.data.T, axis=1), label=\"Original PSD\", color=\"black\")\n",
    "    plt.plot(freq_dim, np.average(whitened_psd.T, axis=1), label=\"Whitened PSD\", color=\"red\")\n",
    "    plt.ylabel(\"Power\")\n",
    "    plt.xlabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Window \" + str(window) + \" detrending\")\n",
    "    plt.savefig(f\"{base_dir}/images/{prefix}_{window}\", dpi=300, bbox_inches=\"tight\") \n",
    "    plt.close()\n",
    "\n",
    "    # Convert the whitened psd to stc, then save it\n",
    "    whitened_psd_stc = mne.SourceEstimate(\n",
    "        data=whitened_psd,\n",
    "        vertices=stc.vertices,\n",
    "        tmin=0, \n",
    "        tstep=1\n",
    "        )\n",
    "    whitened_psd_stc.save(f\"{base_dir}/output/{prefix}_whitened_window{window}\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c224a638",
   "metadata": {},
   "source": [
    "### Canonical bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dfdbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BREAK WHITENED STCS INTO FREQUENCY BANDS\n",
    "\n",
    "#bands = {'delta' : [1, 4], 'theta' : [4, 7], 'alpha' : [8, 12], 'beta' : [15, 29], 'low_gamma' : [30, 40]}\n",
    "bands = {'theta' : [4, 7], 'alpha' : [8, 12]}\n",
    "\n",
    "for band in bands: \n",
    "\n",
    "    low = bands[band][0]\n",
    "    high = bands[band][1]\n",
    "\n",
    "    new_data = np.zeros(shape = (N_VERTICES, N_WINDOWS)) # num vertices x num windows\n",
    "\n",
    "    # Loop through time windows\n",
    "    for window in range(N_WINDOWS): \n",
    "\n",
    "        stc = mne.read_source_estimate(f\"{base_dir}/output/{prefix}_whitened_window{window}\")\n",
    "\n",
    "        trimmed_data = stc.data[:, (stc.times <= high) & (stc.times >= low)]\n",
    "        average_in_this_window = trimmed_data.mean(axis=1) # Compute average across all freqs\n",
    "\n",
    "        new_data[:, window] = average_in_this_window\n",
    "\n",
    "    new_stc = mne.SourceEstimate(\n",
    "        data=new_data, \n",
    "        vertices=stc.vertices,\n",
    "        tmin=0, \n",
    "        tstep=1\n",
    "        )\n",
    "    \n",
    "    new_stc.save(f\"{base_dir}/output/{prefix}_whitened_{band}\", overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
